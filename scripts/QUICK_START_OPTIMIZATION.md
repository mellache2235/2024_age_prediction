# Quick Start Guide: Optimized Brain-Behavior Analysis

## ğŸ¯ Goal
**Maximize Spearman correlations** between IG features and behavioral measures using comprehensive optimization.

---

## ğŸš€ Quick Start

### Run Full Analysis
```bash
cd /Users/hari/Desktop/SCSNL/2024_age_prediction
python scripts/run_stanford_asd_brain_behavior_optimized.py
```

### Test First (Recommended)
```bash
# Test with just 2 behavioral measures (~5 min)
python scripts/run_stanford_asd_brain_behavior_optimized.py --max-measures 2

# Verify installation
python3 scripts/test_optimized_script.py
```

---

## ğŸ“Š What Gets Optimized

The script automatically tests **4 optimization strategies**:

1. **PCA + Regression** â† Good for dense patterns
2. **PLS Regression** â† Best for prediction tasks  
3. **Feature Selection** â† Best when few regions matter
4. **Direct Regression** â† Baseline comparison

For each strategy, it tests:
- Multiple regression models (Linear, Ridge, Lasso, ElasticNet)
- Different hyperparameters (components, alphas, k-features)
- **Total: ~100-200 configurations per behavioral measure**

---

## ğŸ“ˆ Expected Results

### Correlation Improvements
Compared to original script:
- Original: Ï = 0.15-0.35
- Optimized: Ï = 0.25-0.55  
- **Improvement: +10-30%** on average

### Computation Time
- Original: 2-5 minutes
- Optimized: 20-60 minutes (depends on # of measures)
- With `--max-measures 3`: ~5-10 minutes

---

## ğŸ“ Output Files

### Location
```
/oak/stanford/groups/menon/projects/mellache/2024_age_prediction_test/
results/brain_behavior/stanford_asd_optimized/
```

### Key Files
| File | Description |
|------|-------------|
| `optimization_summary.csv` | **Best configuration per behavioral measure** â­ |
| `optimization_results_*.csv` | All tested configurations |
| `scatter_*_optimized.png` | Visualization (PNG) |
| `scatter_*_optimized.tiff` | High-res for publication |
| `scatter_*_optimized.ai` | Vector format for editing |

---

## ğŸ” Interpreting Results

### Summary CSV
Look for these columns:

```csv
Measure,Final_Spearman,Best_Strategy,Best_Model,CV_Spearman,Final_P_Value
srs_total_score_standard,0.481,PLS,PLS,0.452,0.0001
social_awareness_tscore,0.412,PCA+Ridge,Ridge,0.389,0.0008
```

**Key Metrics**:
- `Final_Spearman`: **Most important** - final correlation
- `CV_Spearman`: Cross-validated correlation (more reliable)
- `Final_P_Value`: Statistical significance
- `Best_Strategy`: What worked best for this measure
- `Best_Model`: Which regression model won

### What Makes a Good Result?
- âœ… **Excellent**: Ï > 0.5, p < 0.001
- âœ… **Good**: Ï > 0.3, p < 0.01
- âœ… **Moderate**: Ï > 0.2, p < 0.05
- âš ï¸ **Weak**: Ï < 0.2 (may not be reliable)

---

## âš™ï¸ Command-Line Options

```bash
# Full analysis (default)
python run_stanford_asd_brain_behavior_optimized.py

# Test mode (2 measures)
python run_stanford_asd_brain_behavior_optimized.py --max-measures 2

# Sequential processing (1 core, good for debugging)
python run_stanford_asd_brain_behavior_optimized.py --n-jobs 1

# Use 4 cores
python run_stanford_asd_brain_behavior_optimized.py --n-jobs 4

# Use all cores (default)
python run_stanford_asd_brain_behavior_optimized.py --n-jobs -1
```

---

## ğŸ†š When to Use Which Script?

### Use Optimized Script (`*_optimized.py`) When:
- âœ… You want **maximum correlations**
- âœ… Publishing results (need robust CV)
- âœ… Testing which brain regions matter most
- âœ… Comparing different behavioral measures
- âœ… Time is not critical (~30-60 min acceptable)

### Use Original Script (`*_enhanced.py`) When:
- âœ… Quick exploratory analysis
- âœ… Just want to see if there's any relationship
- âœ… Need results in <5 minutes
- âœ… Standard PCA approach is sufficient

---

## ğŸ› Common Issues

### "Insufficient data" warning
**Cause**: Behavioral measure has too few subjects  
**Solution**: Check for missing values in behavioral data

### Script is slow
**Solutions**:
```bash
# Option 1: Test with fewer measures
python run_stanford_asd_brain_behavior_optimized.py --max-measures 2

# Option 2: Use fewer cores
python run_stanford_asd_brain_behavior_optimized.py --n-jobs 1
```

### Low correlations (all Ï < 0.2)
**Possible causes**:
- Weak brain-behavior relationship (this is normal for some measures)
- Data quality issues
- IG features not relevant to this behavior

**Check**:
- Are behavioral scores properly scaled?
- Do subjects have valid IG scores?
- Try different behavioral measures

---

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| `QUICK_START_OPTIMIZATION.md` | This file - quick reference |
| `OPTIMIZATION_SUMMARY.md` | Implementation details & results |
| `OPTIMIZATION_README.md` | Full documentation (300+ lines) |
| `test_optimized_script.py` | Test suite |

---

## ğŸ”¬ Behind the Scenes

### What the Script Does (Simplified)
```
For each behavioral measure:
  1. Load IG features + behavioral scores
  2. Remove outliers (IQR method)
  3. Test ~100-200 configurations:
     - PCA (5-50 components) + 4 models
     - PLS (3-30 components)
     - Feature selection (50-200 features) + models
     - Direct regression with regularization
  4. Pick configuration with highest CV Spearman Ï
  5. Evaluate on full data
  6. Save results + visualizations
```

### Why It Works Better
1. **PLS** optimizes covariance (X,y), not just variance (X)
2. **Feature selection** removes noisy brain regions
3. **Regularization** prevents overfitting
4. **Cross-validation** ensures generalizability

---

## âœ… Checklist

Before running:
- [ ] IG CSV file exists and has subject_id column
- [ ] Behavioral CSV has subject_id column
- [ ] Behavioral measures are numeric (not text)
- [ ] Sufficient overlap between IG and behavioral subjects (N â‰¥ 30)

After running:
- [ ] Check `optimization_summary.csv` for best results
- [ ] Review scatter plots for top correlations
- [ ] Note which strategy worked best (PCA/PLS/FeatureSelection)
- [ ] Check CV vs final Spearman (should be similar)

---

## ğŸ’¡ Pro Tips

1. **Start with `--max-measures 2`** to test everything works
2. **Check CV_Spearman first** - it's more reliable than Final_Spearman
3. **If CV and Final differ a lot (>0.1)**, you may have overfitting
4. **Compare strategies** - some measures work better with PLS, others with PCA
5. **Look at p-values** - even moderate Ï can be significant with large N

---

## ğŸ“ Need Help?

1. Run test suite: `python3 scripts/test_optimized_script.py`
2. Check full documentation: `OPTIMIZATION_README.md`
3. Review implementation: `OPTIMIZATION_SUMMARY.md`
4. Contact research team

---

**Last Updated**: October 2024  
**Status**: âœ… Tested & Ready

