# Brain-Behavior Optimization Guide

## üéØ Goal
Maximize Spearman correlations between brain features (IG scores) and behavioral measures using comprehensive hyperparameter optimization.

---

## ‚úÖ Reproducibility

All scripts use **random seed = 42** for:
- Cross-validation splits
- Model initialization
- Any stochastic processes

**Result**: Running the same script twice produces **identical results** - critical for scientific reproducibility!

---

## üìã Step-by-Step Workflow

### Step 1: Run Optimization

Choose the appropriate script for your cohort:

#### Dedicated Scripts (Recommended):
```bash
# Stanford ASD (SRS measures)
python scripts/run_stanford_asd_brain_behavior_optimized.py

# ABIDE ASD (ADOS measures)
python scripts/run_abide_asd_brain_behavior_optimized.py

# NKI (filters to core ADHD measures)
python scripts/run_nki_brain_behavior_optimized.py
```

**Note**: NKI script automatically filters to most relevant measures (Hyperactivity, Inattention, Impulsivity) from CAARS/Conners files for focused analysis.

#### Universal Script (ADHD cohorts):
```bash
# ADHD200 or CMI-HBN
python scripts/run_all_cohorts_brain_behavior_optimized.py --cohort adhd200_td
python scripts/run_all_cohorts_brain_behavior_optimized.py --cohort adhd200_adhd
python scripts/run_all_cohorts_brain_behavior_optimized.py --cohort cmihbn_td
python scripts/run_all_cohorts_brain_behavior_optimized.py --cohort cmihbn_adhd
```

**Test mode** (2 measures, ~5 min):
```bash
python scripts/run_stanford_asd_brain_behavior_optimized.py --max-measures 2
```

**Runtime**: 30-60 minutes for full analysis

---

### Step 2: What Happens During Optimization

For each behavioral measure, the script:

1. **Loads data** (IG features + behavioral scores)
2. **Removes outliers** (IQR √ó 3 method)
3. **Tests ~100-200 configurations**:
   - PCA + Regression (5-50 components √ó 4 models √ó 7 alphas)
   - PLS Regression (3-30 components)
   - Feature Selection + Regression (4 feature counts √ó 2 methods)
   - Direct Regularized Regression (7 alphas)
4. **Uses 5-fold cross-validation** for each config
5. **Selects best configuration** (highest CV Spearman œÅ)
6. **Refits best model on ALL data**
7. **Evaluates and saves results**

**Expected warnings**: `SpearmanRConstantInputWarning` (20-50 times) - NORMAL! Bad configs being tested and rejected.

---

### Step 3: Review Console Output

For each behavioral measure, you'll see:

```
====================================================================================================
  ANALYZING: social_awareness_tscore
====================================================================================================

  Valid subjects: 99
  
  Optimizing social_awareness_tscore...
    Best: FeatureSelection+Lasso (œÅ=0.0964)  ‚Üê CV score

üìä PREDICTION INTEGRITY CHECK:
================================================================================

Actual values:
  N = 99
  Mean = 65.23, Std = 12.45, Range = [42.00, 95.00]

Predicted values:
  Mean = 64.87, Std = 11.98, Range = [45.12, 88.34]

Metrics:
  Spearman œÅ = 0.293    ‚Üê Final score (on all data)
  P-value = 0.0033      ‚Üê Significance
  R¬≤ = 0.095
  MAE = 5.26

‚úÖ No major issues detected  ‚Üê GOOD! Use this result

Sample predictions (first 5):
    Actual  Predicted   Residual
     65.20      63.40       1.80
     72.10      74.30      -2.20
     58.90      60.10      -1.20
     81.50      79.20       2.30
     55.00      57.80      -2.80
================================================================================

‚úì Saved: scatter_social_awareness_tscore_FeatureSelection_Lasso_k50_optimized.png
```

**Key things to check**:
- ‚úÖ or ‚ùå in integrity check
- Spearman œÅ and p-value
- Prediction range (should be reasonable, not [-1000, 2000])

---

### Step 4: FDR Correction Applied

If multiple behavioral measures are analyzed (>1), the script automatically applies **Benjamini-Hochberg FDR correction**:

```
[STEP Applying FDR correction] Benjamini-Hochberg across 8 measures
----------------------------------------------------------------------------------------------------

Significant before FDR: 5/8
Significant after FDR:  3/8

‚úÖ Measures surviving FDR correction (Œ± = 0.05):
  B T-SCORE (HYPERACTIVITY/RESTLESSNESS)........................ œÅ=0.412, p<0.001, p_FDR=0.002
  A TOTAL (INATTENTION/MEMORY PROBLEMS)......................... œÅ=0.353, p=0.001, p_FDR=0.004
  F TOTAL (DSM-5 HYPERACTIVE-IMPULSIVE SYMPTOMS)................ œÅ=0.334, p=0.002, p_FDR=0.006
```

**Use only measures that survive FDR correction** for publication!

---

### Step 5: Files Produced

For each cohort, in `/oak/.../brain_behavior/{cohort}_optimized/`:

#### Summary Files:
- **`optimization_summary.csv`** - Best configuration for each measure
  ```csv
  Measure,N_Subjects,Best_Strategy,Best_Model,CV_Spearman,Final_Spearman,Final_P_Value,Final_R2
  social_awareness_tscore,99,FeatureSelection+Lasso,Lasso,0.096,0.293,0.0033,0.095
  ```

#### Per-Measure Files:
- **`scatter_{measure}_{method}_{params}_optimized.png/tiff/ai`** - Scatter plot
  - Example: `scatter_social_awareness_tscore_FeatureSelection_Lasso_k50_optimized.png`
  - Shows: r = 0.293, p = 0.0033, model info
  
- **`predictions_{measure}_{method}.csv`** - Actual vs predicted values
  ```csv
  Actual,Predicted,Residual
  65.20,63.40,1.80
  72.10,74.30,-2.20
  ...
  ```

- **`optimization_results_{measure}.csv`** - All ~200 configurations tested
  ```csv
  strategy,model,n_components,alpha,mean_cv_spearman,std_cv_spearman
  FeatureSelection+Lasso,Lasso,,0.1,0.0964,0.0234
  PLS,PLS,15,,0.0893,0.0198
  ...
  ```

---

### Step 5: Identify Good Results

#### Option 1: Check Console Output
Look for:
- ‚úÖ **"No major issues detected"** ‚Üí Use this result
- ‚ùå **"ISSUES DETECTED"** ‚Üí Don't use

#### Option 2: Use Summary Script
```bash
python scripts/create_optimization_summary_figure.py --cohort stanford_asd --min-rho 0.2
```

**Produces**:
- `{cohort}_optimization_summary_significant.csv` - Only good results
- `{cohort}_correlations_barplot.png` - Visual summary
- `{cohort}_optimization_summary_figure.png` - Multi-panel figure

**Automatically filters out**:
- Failed models (extreme R¬≤)
- Non-significant results (p > 0.05)
- Weak correlations (|œÅ| < threshold)

---

## üìä Interpreting Results

### ‚úÖ Good Result
```
Measure: social_awareness_tscore
Spearman œÅ: 0.293, P-value: 0.0033, R¬≤: 0.095
Best: FeatureSelection+Lasso (k=50 features, Œ±=0.1)
‚úÖ No major issues detected
```

**What to do**: 
- ‚úì Use this result for publication
- ‚úì Use the scatter plot
- ‚úì Report: "œÅ = 0.29, p < 0.01, using feature selection"

---

### ‚ùå Failed Result
```
Measure: srs_total_score_standard
Spearman œÅ: -0.022, P-value: 0.827, R¬≤: -6484
Best: PLS (but still terrible)
üö® ISSUES DETECTED: Extreme R¬≤, High MAE
```

**What to do**:
- ‚úó Don't use this result
- ‚úó Don't include in publication
- ‚úì Note: "No significant brain-behavior correlation found for this measure"

---

## üîç Optimization Details

### What Gets Tested (~200 configurations):

| Strategy | Configurations |
|----------|----------------|
| **PCA + Linear** | 10 PC values = 10 configs |
| **PCA + Ridge** | 10 PC √ó 7 alphas = 70 configs |
| **PCA + Lasso** | 10 PC √ó 7 alphas = 70 configs |
| **PCA + ElasticNet** | 10 PC √ó 7 alphas = 70 configs |
| **PLS** | 10 component values = 10 configs |
| **Feature Selection + Ridge/Lasso** | 2 methods √ó 4 K √ó 2 models √ó 4 alphas = 64 configs |
| **Direct Ridge/Lasso/ElasticNet** | 3 models √ó 7 alphas = 21 configs |
| **Total** | ~315 configurations |

### How Selection Works:
- Each config evaluated with 5-fold cross-validation
- **Spearman correlation** is the metric being maximized
- Best config (highest CV Spearman) is selected
- Best model refitted on ALL data
- Final performance reported

---

## üìà Expected Performance

### Baseline (Enhanced Scripts):
- Uses: PCA (80% variance) + LinearRegression
- Example NKI: œÅ = 0.35 - 0.41

### Optimized (Should Achieve):
- Tests: All strategies above
- Expected: œÅ = baseline to +30%
- Example NKI: œÅ = 0.41 - 0.50

**If optimized ‚âà baseline**: LinearRegression was already optimal!  
**If optimized > baseline (+10-30%)**: PLS or other strategy worked better!

---

## üö® Common Issues

### Issue: "Per-column arrays must be 1-dimensional"
**Cause**: Running old code on Oak  
**Solution**: Ensure latest code is synced/cloned to Oak

### Issue: Many SpearmanRConstantInputWarnings
**Status**: **NORMAL!** ‚úÖ Part of testing ~200 configs  
**Action**: None needed - bad configs auto-rejected

### Issue: Poor performance (œÅ much worse than baseline)
**Causes**:
1. No real brain-behavior relationship (expected for some measures)
2. Data mismatch (wrong subjects loaded)
3. Old code on Oak (sync issue)

**Check**: Integrity output should show reasonable prediction ranges

---

## üìö Summary Table

| Step | Command | Output | Time |
|------|---------|--------|------|
| **1. Run Optimization** | `python run_{cohort}_optimized.py` | Tests ~200 configs | 30-60 min |
| **2. Check Console** | (automatic) | Integrity checks shown | Real-time |
| **3. Review Results** | Check for ‚úÖ vs ‚ùå | Identify good measures | 1 min |
| **4. Create Summary** | `create_optimization_summary_figure.py` | Filtered results only | 1 min |
| **5. Use in Paper** | Copy .tiff files | Publication figures | Done! |

---

## üéØ Quick Checklist

Before running:
- [ ] Scripts are synced to Oak (if running there)
- [ ] IG CSV file exists
- [ ] Behavioral data exists

After running:
- [ ] Check for "No major issues detected" ‚úÖ
- [ ] Verify p-value < 0.05
- [ ] Verify |œÅ| > 0.2 (or your threshold)
- [ ] Check prediction ranges are reasonable
- [ ] Only use measures that passed all checks

For publication:
- [ ] Use measures with ‚úÖ in integrity check
- [ ] Report both CV and Final Spearman
- [ ] Include p-values
- [ ] Note optimization method in methods section

---

## üìû All Cohorts Quick Reference

```bash
# Stanford ASD
python scripts/run_stanford_asd_brain_behavior_optimized.py

# ABIDE ASD  
python scripts/run_abide_asd_brain_behavior_optimized.py

# NKI
python scripts/run_nki_brain_behavior_optimized.py

# ADHD200 TD/ADHD, CMI-HBN TD/ADHD
python scripts/run_all_cohorts_brain_behavior_optimized.py --cohort {cohort_name}
```

**All produce same outputs**: optimization_summary.csv, scatter plots, predictions CSV, etc.

---

**That's it!** One guide for everything. üéâ

